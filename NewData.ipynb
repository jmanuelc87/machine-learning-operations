{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loads the original ENB2012 dataset\n",
    "2. Generates synthetic data that preserves:\n",
    "\n",
    "- Statistical distributions of each feature\n",
    "- Correlations between features\n",
    "- Domain constraints (e.g., positive values for areas)\n",
    "\n",
    "\n",
    "Includes:\n",
    "- Validation to ensure the synthetic data matches the original distribution\n",
    "- Outputs the data in CSV format ready for your MLops pipeline\n",
    "\n",
    "To use this script:\n",
    "\n",
    "1. Place your ENB2012_data.csv file in the same directory as the script\n",
    "2. Run the script to generate synthetic_ENB2012_data.csv\n",
    "3. The script will print validation metrics showing how well the synthetic data matches the original\n",
    "\n",
    "The synthetic data preserves important properties like:\n",
    "\n",
    "* Relative Compactness staying between 0 and 1\n",
    "* Orientation values at 45-degree intervals\n",
    "* Positive values for areas and loads\n",
    "* Discrete values for Glazing Area Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original data...\n",
      "Original data shape: (1296, 10)\n",
      "\n",
      "Generating synthetic data...\n",
      "Synthetic data shape: (5184, 10)\n",
      "\n",
      "Validating synthetic data...\n",
      "\n",
      "Synthetic data saved to synthetic_ENB2012_data.csv\n",
      "\n",
      "Validation Summary:\n",
      "\n",
      "Relative_Compactness:\n",
      "KS statistic: nan\n",
      "Mean difference: 0.01%\n",
      "Std difference: -1.71%\n",
      "\n",
      "Surface_Area:\n",
      "KS statistic: nan\n",
      "Mean difference: -0.28%\n",
      "Std difference: -7.85%\n",
      "\n",
      "Wall_Area:\n",
      "KS statistic: nan\n",
      "Mean difference: 0.35%\n",
      "Std difference: -5.48%\n",
      "\n",
      "Roof_Area:\n",
      "KS statistic: nan\n",
      "Mean difference: -1.23%\n",
      "Std difference: -20.61%\n",
      "\n",
      "Overall_Height:\n",
      "KS statistic: nan\n",
      "Mean difference: -0.29%\n",
      "Std difference: -28.51%\n",
      "\n",
      "Orientation:\n",
      "KS statistic: nan\n",
      "Mean difference: 4356.10%\n",
      "Std difference: 9105.61%\n",
      "\n",
      "Glazing_Area:\n",
      "KS statistic: nan\n",
      "Mean difference: -2.99%\n",
      "Std difference: -12.13%\n",
      "\n",
      "Glazing_Area_Distribution:\n",
      "KS statistic: nan\n",
      "Mean difference: -10.47%\n",
      "Std difference: 10.66%\n",
      "\n",
      "Heating_Load:\n",
      "KS statistic: nan\n",
      "Mean difference: 1.06%\n",
      "Std difference: -5.98%\n",
      "\n",
      "Cooling_Load:\n",
      "KS statistic: nan\n",
      "Mean difference: 1.70%\n",
      "Std difference: -6.64%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "def load_original_data():\n",
    "    \"\"\"Load the original ENB2012 dataset\"\"\"\n",
    "    try:\n",
    "        # Try to load with default numeric columns (X1, X2, etc.)\n",
    "        df = pd.read_csv('ENB2012_data.csv')\n",
    "        \n",
    "        # Rename columns to meaningful names\n",
    "        column_names = {\n",
    "            'X1': 'Relative_Compactness', \n",
    "            'X2': 'Surface_Area',\n",
    "            'X3': 'Wall_Area',\n",
    "            'X4': 'Roof_Area',\n",
    "            'X5': 'Overall_Height',\n",
    "            'X6': 'Orientation',\n",
    "            'X7': 'Glazing_Area',\n",
    "            'X8': 'Glazing_Area_Distribution',\n",
    "            'Y1': 'Heating_Load',\n",
    "            'Y2': 'Cooling_Load'\n",
    "        }\n",
    "        \n",
    "        df = df.rename(columns=column_names)\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def generate_synthetic_data(original_data, multiplier=4, random_state=42):\n",
    "    \"\"\"\n",
    "    Generate synthetic data using a simplified approach with individual column distributions\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Number of samples to generate\n",
    "    n_synthetic = len(original_data) * multiplier\n",
    "    \n",
    "    # Create empty DataFrame for synthetic data\n",
    "    synthetic_df = pd.DataFrame()\n",
    "    \n",
    "    # Generate synthetic data for each column independently\n",
    "    for column in original_data.columns:\n",
    "        # Get original column data\n",
    "        orig_data = original_data[column].astype(float)\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        mean = orig_data.mean()\n",
    "        std = orig_data.std()\n",
    "        \n",
    "        # Generate synthetic values\n",
    "        if column == 'Orientation':\n",
    "            # Generate random orientations (0, 45, 90, 135, 180, 225, 270, 315)\n",
    "            synthetic_values = np.random.choice([0, 45, 90, 135, 180, 225, 270, 315], size=n_synthetic)\n",
    "        \n",
    "        elif column == 'Glazing_Area_Distribution':\n",
    "            # Generate discrete values between 0 and 5\n",
    "            synthetic_values = np.random.randint(0, 6, size=n_synthetic)\n",
    "        \n",
    "        elif column == 'Relative_Compactness':\n",
    "            # Generate values between 0 and 1\n",
    "            synthetic_values = np.random.normal(mean, std, n_synthetic)\n",
    "            synthetic_values = np.clip(synthetic_values, 0, 1)\n",
    "        \n",
    "        else:\n",
    "            # Generate normally distributed values\n",
    "            synthetic_values = np.random.normal(mean, std, n_synthetic)\n",
    "            \n",
    "            # Ensure positive values for areas and loads\n",
    "            if column in ['Surface_Area', 'Wall_Area', 'Roof_Area', 'Heating_Load', 'Cooling_Load']:\n",
    "                synthetic_values = np.abs(synthetic_values)\n",
    "            \n",
    "            # Clip to original range\n",
    "            min_val = orig_data.min()\n",
    "            max_val = orig_data.max()\n",
    "            synthetic_values = np.clip(synthetic_values, min_val, max_val)\n",
    "        \n",
    "        synthetic_df[column] = synthetic_values\n",
    "    \n",
    "    return synthetic_df\n",
    "\n",
    "def validate_synthetic_data(original_data, synthetic_data):\n",
    "    \"\"\"\n",
    "    Validate the synthetic data by comparing distributions with original data\n",
    "    \"\"\"\n",
    "    validation_results = {}\n",
    "    \n",
    "    # Compare basic statistics\n",
    "    for column in original_data.columns:\n",
    "        orig_stats = original_data[column].describe()\n",
    "        synt_stats = synthetic_data[column].describe()\n",
    "        \n",
    "        # Perform Kolmogorov-Smirnov test\n",
    "        ks_statistic, p_value = stats.ks_2samp(\n",
    "            original_data[column].astype(float),\n",
    "            synthetic_data[column].astype(float)\n",
    "        )\n",
    "        \n",
    "        validation_results[column] = {\n",
    "            'ks_statistic': ks_statistic,\n",
    "            'p_value': p_value,\n",
    "            'mean_diff_percent': ((synt_stats['mean'] - orig_stats['mean']) / orig_stats['mean']) * 100,\n",
    "            'std_diff_percent': ((synt_stats['std'] - orig_stats['std']) / orig_stats['std']) * 100\n",
    "        }\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Load original data\n",
    "        print(\"Loading original data...\")\n",
    "        original_data = load_original_data()\n",
    "        print(\"Original data shape:\", original_data.shape)\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        print(\"\\nGenerating synthetic data...\")\n",
    "        synthetic_data = generate_synthetic_data(original_data, multiplier=4)\n",
    "        print(\"Synthetic data shape:\", synthetic_data.shape)\n",
    "        \n",
    "        # Validate synthetic data\n",
    "        print(\"\\nValidating synthetic data...\")\n",
    "        validation_results = validate_synthetic_data(original_data, synthetic_data)\n",
    "        \n",
    "        # Save synthetic data to CSV\n",
    "        output_file = 'synthetic_ENB2012_data.csv'\n",
    "        synthetic_data.to_csv(output_file, index=False)\n",
    "        print(f\"\\nSynthetic data saved to {output_file}\")\n",
    "        \n",
    "        # Print validation summary\n",
    "        print(\"\\nValidation Summary:\")\n",
    "        for column, metrics in validation_results.items():\n",
    "            print(f\"\\n{column}:\")\n",
    "            print(f\"KS statistic: {metrics['ks_statistic']:.4f}\")\n",
    "            print(f\"Mean difference: {metrics['mean_diff_percent']:.2f}%\")\n",
    "            print(f\"Std difference: {metrics['std_diff_percent']:.2f}%\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
